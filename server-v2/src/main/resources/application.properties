# ============================================================================
# Spring Boot Application Configuration - Assignment 3
# ChatFlow WebSocket Server with Aurora PostgreSQL Persistence
# ============================================================================

# ============================================================================
# Server Configuration
# ============================================================================
server.port=8080
spring.application.name=chatflow-server

# Unique server identifier (change for each instance)
server.id=server-1

# Tomcat Configuration for High Concurrency
server.tomcat.threads.max=300
server.tomcat.threads.min-spare=50
server.tomcat.max-connections=10000
server.tomcat.accept-count=5000
server.tomcat.connection-timeout=60000

# ============================================================================
# WebSocket Configuration
# ============================================================================
websocket.writer.threads=50

# ============================================================================
# AWS Configuration
# ============================================================================
aws.region=us-west-2

# ============================================================================
# SQS Configuration
# ============================================================================
sqs.queue.prefix=chatflow-room-
sqs.fifo.enabled=true

# Queue URL retry configuration
sqs.queue.retry.interval.ms=60000

# ============================================================================
# SQS Consumer Configuration
# ============================================================================
sqs.consumer.enabled=true
sqs.consumer.threads=25
sqs.consumer.max.messages=10
sqs.consumer.wait.time=20
sqs.consumer.visibility.timeout=30

# ============================================================================
# Consumer Partitioning (Multi-instance support)
# ============================================================================
# Enable when running multiple instances behind ALB
consumer.partition.enabled=false

# Comma-separated list of all server IDs in deployment
# For multi-instance: server-1,server-2,server-3,server-4
consumer.partition.servers=server-1,server2,server3,server4

# ============================================================================
# SQS Batch Publishing (Cost optimization)
# ============================================================================
# Enable to reduce API calls by ~10x
sqs.batch.enabled=false
sqs.batch.max.size=10
sqs.batch.flush.interval.ms=100

# ============================================================================
# Assignment 3: PostgreSQL Database Configuration
# ============================================================================
# IMPORTANT: Replace xxxxx with your actual Aurora cluster endpoint
spring.datasource.url=jdbc:postgresql://cs6650-chatflow.cluster-<your-cluster-endpoint>.us-west-2.rds.amazonaws.com:5432/chatdb
spring.datasource.username=db_admin
spring.datasource.password=${DB_PASSWORD}
spring.datasource.driver-class-name=org.postgresql.Driver

# ============================================================================
# HikariCP Connection Pool Configuration
# ============================================================================
# Pool sizing
spring.datasource.hikari.maximum-pool-size=50
spring.datasource.hikari.minimum-idle=10
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.idle-timeout=600000
spring.datasource.hikari.max-lifetime=1800000
spring.datasource.hikari.pool-name=ChatFlowPGPool

# Connection tuning
spring.datasource.hikari.connection-init-sql=SELECT 1
spring.datasource.hikari.validation-timeout=5000
spring.datasource.hikari.leak-detection-threshold=60000

# CRITICAL: Prepared Statement Caching (10-20% performance boost)
spring.datasource.hikari.data-source-properties.cachePrepStmts=true
spring.datasource.hikari.data-source-properties.prepStmtCacheSize=250
spring.datasource.hikari.data-source-properties.prepStmtCacheSqlLimit=2048

# CRITICAL: Batch rewrite for PostgreSQL (2-3x faster batch inserts)
spring.datasource.hikari.data-source-properties.reWriteBatchedInserts=true

# ============================================================================
# Assignment 3: Batch Writer Configuration
# ============================================================================
# Test different configurations for optimal performance:
#
# Config 1: Small batches, fast flush (low latency, lower throughput)
#   batch.writer.size=100
#   batch.writer.flush.interval.ms=100
#
# Config 2: Medium batches, medium flush (balanced)
#   batch.writer.size=500
#   batch.writer.flush.interval.ms=500
#
# Config 3: Large batches, 1s flush (RECOMMENDED - optimal throughput)
#   batch.writer.size=1000
#   batch.writer.flush.interval.ms=1000
#
# Config 4: Very large batches (maximum throughput)
#   batch.writer.size=5000
#   batch.writer.flush.interval.ms=1000

# RECOMMENDED CONFIGURATION (Config 3)
batch.writer.size=1000
batch.writer.flush.interval.ms=1000

# Buffer capacity (max messages in memory before blocking/dropping)
batch.writer.buffer.capacity=10000

# ============================================================================
# Assignment 3: Dead Letter Queue Configuration
# ============================================================================
# Enable DLQ for failed database writes
dlq.enabled=true

# DLQ queue name (FIFO queue for ordering)
dlq.queue.name=chatflow-db-dlq.fifo

# ============================================================================
# Assignment 3: Metrics Configuration
# ============================================================================
# Maximum results returned by core queries (prevent large result sets)
metrics.query.max.results=1000

# ============================================================================
# Thread Pool Configuration
# ============================================================================
spring.task.execution.pool.core-size=50
spring.task.execution.pool.max-size=200
spring.task.execution.pool.queue-capacity=10000

# ============================================================================
# Logging Configuration
# ============================================================================
logging.level.root=INFO
logging.level.com.chatflow=INFO
logging.level.com.zaxxer.hikari=INFO
logging.level.org.springframework.messaging=WARN
logging.level.org.springframework.web.socket=WARN
logging.level.org.springframework.jdbc=INFO
logging.level.software.amazon.awssdk=WARN

# ============================================================================
# Jackson Configuration
# ============================================================================
spring.jackson.serialization.write-dates-as-timestamps=false
spring.jackson.time-zone=UTC

# ============================================================================
# CONFIGURATION NOTES
# ============================================================================
#
# Single Instance Setup (For Assignment 3):
#   - consumer.partition.enabled=false
#   - sqs.consumer.threads=25
#   - batch.writer.size=1000
#   - batch.writer.flush.interval.ms=1000
#
# Multi-Instance Setup (Optional - Advanced):
#   - consumer.partition.enabled=true
#   - consumer.partition.servers=server-1,server-2,server-3,server-4
#   - sqs.consumer.threads=10 (each instance handles 5 rooms)
#   - Change server.id for each instance
#
# Before Starting:
#   1. Replace xxxxx in spring.datasource.url with your Aurora endpoint
#   2. Set DB_PASSWORD environment variable: export DB_PASSWORD="your-password"
#   3. Ensure Aurora security group allows connections from EC2
#   4. Run schema.sql to initialize database
#
# Performance Tuning:
#   - Test batch.writer.size: 100, 500, 1000, 5000
#   - Test batch.writer.flush.interval.ms: 100, 500, 1000
#   - Record throughput and latency for each configuration
#   - Recommended: size=1000, interval=1000 (best balance)